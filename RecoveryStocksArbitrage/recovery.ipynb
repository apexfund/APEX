{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import gc\n",
    "import joblib\n",
    "import pathlib\n",
    "import json\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# visualize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "sns.set_context(\"talk\")\n",
    "style.use('seaborn-colorblind')\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import yfinance as yf\n",
    "import statistics as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df = df[df['Ticker'].notna()]\n",
    "    df = df.replace(to_replace=r' [A-Z]+ Equity|Bond|ETF', value='', regex=True)\n",
    "    df = df.replace(to_replace=r' ', value='', regex=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_historical_data(df, start_date, end_date, inter):\n",
    "    # Data gathering\n",
    "    historical_data = dict()\n",
    "\n",
    "    # map ticker labels to their corresponding 3mo historical data\n",
    "    for ticker in df['Ticker']:\n",
    "        ticker = ticker.replace(\" \",\"\")\n",
    "        #Lets look at the last 3m of data\n",
    "        data = yf.Ticker(ticker).history(start=start_date, end=end_date, interval=inter)\n",
    "        # Add day of the week so we can start to see weekly patterns\n",
    "        data = data.reset_index(0)\n",
    "        data['Dayofweek'] = pd.to_datetime(data['Date']).dt.dayofweek\n",
    "        data = data.drop(columns=['High','Low','Dividends', 'Stock Splits'])\n",
    "        data['Intraday'] = (data['Close'] / data['Open']) - 1\n",
    "        data = data.reindex(columns = ['Date', 'Dayofweek', 'Open', 'Close', 'Volume', 'Intraday'])\n",
    "        historical_data[ticker] = data\n",
    "\n",
    "    return historical_data\n",
    "\n",
    "    # Here are some of the algorithms we will use to backtest potential trading strategies. \n",
    "def backtest_in_usd(df, day):\n",
    "    # We will start with 1000 usd.\n",
    "    # This backtest will test buying shares at market open and selling at market close on certain days of the week only.\n",
    "    # starting cash\n",
    "    usd = 1000\n",
    "    profits = []\n",
    "    for i in range(len(df)):\n",
    "        if df['Dayofweek'].values[i] == day:\n",
    "            # buy\n",
    "            pos_volume = usd / df['Open'].values[i]\n",
    "            # calculate the change based on close-open\n",
    "            usd += pos_volume * (df['Close'].values[i] - df['Open'].values[i])\n",
    "            # append profits to the array \n",
    "            profits.append(pos_volume * (df['Close'].values[i] - df['Open'].values[i]))\n",
    "    return profits\n",
    "\n",
    "def backtest_in_percent(df, day):\n",
    "    # We will start with 1000 usd.\n",
    "    # This backtest will test buying shares at market open and selling at market close on certain days of the week only.\n",
    "    # starting cash\n",
    "    usd = 1000\n",
    "    profits = []\n",
    "    # for each week\n",
    "    for i in range(len(df)):\n",
    "        # only calculate using values on the specified day of week\n",
    "        if df['Dayofweek'].values[i] == day:\n",
    "            # buy\n",
    "            pos_volume = usd / df['Open'].values[i]\n",
    "            # calculate the change\n",
    "            change = pos_volume * (df['Close'].values[i] - df['Open'].values[i])\n",
    "            # append percentage change to array\n",
    "            profits.append(100.0*(change/usd))\n",
    "            # add profits to the start cash\n",
    "            usd += change\n",
    "    return profits\n",
    "\n",
    "def plot_profits_usd(ticker, profits, day):\n",
    "    plt.figure() # create figure\n",
    "    profits = np.array(profits) \n",
    "    plt.plot(np.cumsum(profits)) # plot the cum sum of profits\n",
    "    winp = np.sum(profits > 0) / len(profits)\n",
    "    plt.xlabel('week')\n",
    "    plt.ylabel('profits (USD)')\n",
    "    plt.title(f'Current Ticker = {ticker} P(win) = {winp:.3f} on day {day}')\n",
    "\n",
    "def plot_profits_pct(ticker, profits, day):\n",
    "    plt.figure() # creat figure\n",
    "    profits = np.array(profits)\n",
    "    plt.plot(np.cumsum(profits)) # plot cumsum of profits\n",
    "    winp = np.sum(profits > 0) / len(profits)\n",
    "    plt.xlabel('week')\n",
    "    plt.ylabel('profits (pct)')\n",
    "    plt.title(f'Current Ticker = {ticker} P(win) = {winp:.3f} on day {day}')\n",
    "\n",
    "# given a specific day and a data set, backtest the theory \n",
    "def backtest_per_day(historical_data, day_of_week, in_percent = True, in_dollars= False, gen_plots = True):\n",
    "    backtest_data_pct = dict()\n",
    "    backtest_data_usd = dict()\n",
    "    for ticker, data in historical_data.items():\n",
    "        # Monday - Friday\n",
    "        if in_percent:\n",
    "            # call helper functoin\n",
    "            profits = backtest_in_percent(data, day= day_of_week)\n",
    "            # assign value in df\n",
    "            backtest_data_pct[f'{ticker}_day_{day_of_week}'] = profits\n",
    "            if gen_plots:\n",
    "                # print(ticker, profits)\n",
    "                plot_profits_pct(ticker, profits, day = day_of_week)\n",
    "\n",
    "        if in_dollars:\n",
    "            # call helper function\n",
    "            profits = backtest_in_usd(data, day= day_of_week)\n",
    "            # assign value in df\n",
    "            backtest_data_usd[f'{ticker}_day_{day_of_week}'] = profits\n",
    "            if gen_plots:\n",
    "                # print(ticker, profits)\n",
    "                plot_profits_usd(ticker, profits, day = day_of_week)\n",
    "\n",
    "    if in_percent and not in_dollars:\n",
    "        return backtest_data_pct\n",
    "    elif in_percent and in_dollars:\n",
    "        return backtest_data_pct, backtest_data_usd\n",
    "    else:\n",
    "        return backtest_data_usd\n",
    "\n",
    "# given a dictionary that maps keys to lists and a required length, verify that each list is of required length, else remove\n",
    "def verify_data_length(dictionary, req_len):\n",
    "    bad = []\n",
    "    for k,v in dictionary.items():\n",
    "        if len(v) < req_len:\n",
    "            bad.append(k)\n",
    "    for b in bad:\n",
    "        dictionary.pop(b)\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "# this is the main function that should be called, we shouldnt be using the helpers much outside of this function\n",
    "def backtest(data):\n",
    "    days_of_week = ['Mon', 'Tues', 'Wed', 'Thurs', 'Fri']\n",
    "    backtest_data = dict()\n",
    "    for i in range(len(days_of_week)):\n",
    "        backtest_data[days_of_week[i]] = backtest_per_day(data, day_of_week = i)\n",
    "    \n",
    "    for k,v in backtest_data.items():\n",
    "        backtest_data[k] = verify_data_length(v, (len(v)//5)-1)\n",
    "\n",
    "    return backtest_data\n",
    "\n",
    "# only backtest mondays, i got lazy here and just copy \n",
    "def backtest_monday(data):\n",
    "    days_of_week = ['Mon']\n",
    "    backtest_data = dict()\n",
    "    backtest_data['Mon'] = backtest_per_day(data, day_of_week = 0)    \n",
    "    for k,v in backtest_data.items():\n",
    "        backtest_data[k] = verify_data_length(v, (len(v)//5)-1)\n",
    "\n",
    "    return backtest_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/sandeep/Workspace/APEX/RecoveryStocksArbitrage/Yash_Recovery_Stocks.csv\")\n",
    "df = clean_data(df)\n",
    "\n",
    "historical_data = get_historical_data(df, '2022-08-01', '2022-10-1', '1d')\n",
    "backtest_data = backtest_monday(historical_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yfinance as yf\n",
    "\n",
    "# # Data gathering\n",
    "# historical_data = dict()\n",
    "\n",
    "# # map ticker labels to their corresponding 3mo historical data\n",
    "# for ticker in df['Ticker']:\n",
    "#     ticker = ticker.replace(\" \",\"\")\n",
    "#     #Lets look at the last 3m of data\n",
    "#     data = yf.Ticker(ticker).history(start='2021-11-01', end='2022-01-29', interval=\"1d\")\n",
    "#     # Add day of the week so we can start to see weekly patterns\n",
    "#     data = data.reset_index(0)\n",
    "#     data['Dayofweek'] = pd.to_datetime(data['Date']).dt.dayofweek\n",
    "#     data = data.drop(columns=['High','Low','Dividends', 'Stock Splits'])\n",
    "#     data['Intraday'] = data['Close'] / data['Open']\n",
    "#     data = data.reindex(columns = ['Date', 'Dayofweek', 'Open', 'Close', 'Volume', 'Intraday'])\n",
    "#     historical_data[ticker] = data\n",
    "\n",
    "# backtest_data = dict()\n",
    "# for ticker, data in historical_data.items():\n",
    "#     # print(f'Current Ticker: {ticker}')\n",
    "#     for i in range(0,5):\n",
    "#         profits = backtest_in_percent(data, day= i)\n",
    "#         backtest_data[f'{ticker}_day_{i}'] = profits\n",
    "#         plot_profits_pct(ticker, profits, day = i) \n",
    "\n",
    "# backtest_data_mon = dict()\n",
    "# backtest_data_tue = dict()\n",
    "# backtest_data_wed = dict()\n",
    "# backtest_data_thu = dict()\n",
    "# backtest_data_fri = dict()\n",
    "\n",
    "# for ticker, data in historical_data.items():\n",
    "#     backtest_data_mon[ticker] = backtest_in_percent(data, 0)\n",
    "#     backtest_data_tue[ticker] = backtest_in_percent(data, 1)\n",
    "#     backtest_data_wed[ticker] = backtest_in_percent(data, 2)\n",
    "#     backtest_data_thu[ticker] = backtest_in_percent(data, 3)\n",
    "#     backtest_data_fri[ticker] = backtest_in_percent(data, 4)\n",
    "\n",
    "# # Lets start by analyzing mondays\n",
    "# import statistics as st\n",
    "# # df_mon = pd.DataFrame(backtest_data_mon)\n",
    "\n",
    "# def verify_data_length(dictionary, req_len):\n",
    "#     bad = []\n",
    "#     for k,v in dictionary.items():\n",
    "#         if len(v) < req_len:\n",
    "#             bad.append(k)\n",
    "#     for b in bad:\n",
    "#         dictionary.pop(b)\n",
    "\n",
    "#     return dictionary\n",
    "\n",
    "# backtest_data_mon = verify_data_length(backtest_data_mon, 12)\n",
    "# backtest_data_tue = verify_data_length(backtest_data_tue, 12)\n",
    "# backtest_data_wed= verify_data_length(backtest_data_wed, 12)\n",
    "# backtest_data_thu = verify_data_length(backtest_data_thu, 12)\n",
    "# backtest_data_fri = verify_data_length(backtest_data_fri, 11)\n",
    "# TAX_RATE = 0.35\n",
    "\n",
    "# df_mon = pd.DataFrame(backtest_data_mon)\n",
    "# # df_mon.head()\n",
    "# mon_agg_stats = dict()\n",
    "# for x in df_mon.columns:\n",
    "#    mon_agg_stats[x] = [\"min\", \"max\", \"median\", \"mean\", \"std\"]\n",
    "\n",
    "# mon_stats_df = df_mon.agg(mon_agg_stats)\n",
    "# # mon_stats_df.head()\n",
    "\n",
    "# mon_sharpes = dict()\n",
    "# for tick in mon_stats_df.columns:\n",
    "#     mon_sharpes[tick] = mon_stats_df[tick]['mean']*TAX_RATE / mon_stats_df[tick]['std']\n",
    "# mon_stats_df = mon_stats_df.append(mon_sharpes, ignore_index=True)\n",
    "# mon_stats_df.index = [\"min\", \"max\", \"median\", \"mean\", \"std\", \"sharpe\"]\n",
    "\n",
    "# mon_stats_df = mon_stats_df.transpose()\n",
    "# mon_stats_df.sort_values(axis = 0, by=\"sharpe\", ascending=False)\n",
    "\n",
    "# df_tue = pd.DataFrame(backtest_data_tue)\n",
    "# # df_tue.head()\n",
    "\n",
    "# tue_agg_stats = dict()\n",
    "# for x in df_tue.columns:\n",
    "#    tue_agg_stats[x] = [\"min\", \"max\", \"median\", \"mean\", \"std\"]\n",
    "\n",
    "# tue_stats_df = df_tue.agg(tue_agg_stats)\n",
    "# # tue_stats_df.head()\n",
    "\n",
    "# tue_sharpes = dict()\n",
    "# for tick in tue_stats_df.columns:\n",
    "#    tue_sharpes[tick] = tue_stats_df[tick]['mean']*TAX_RATE / tue_stats_df[tick]['std']\n",
    "# tue_stats_df = tue_stats_df.append(tue_sharpes, ignore_index=True)\n",
    "# tue_stats_df.index = [\"min\", \"max\", \"median\", \"mean\", \"std\", \"sharpe\"]\n",
    "\n",
    "# tue_stats_df = tue_stats_df.transpose()\n",
    "# tue_stats_df.sort_values(axis = 0, by=\"sharpe\", ascending=False)\n",
    "# tue_stats_df\n",
    "\n",
    "# df_wed = pd.DataFrame(backtest_data_wed)\n",
    "# # df_tue.head()\n",
    "\n",
    "# wed_agg_stats = dict()\n",
    "# for x in df_wed.columns:\n",
    "#    wed_agg_stats[x] = [\"min\", \"max\", \"median\", \"mean\", \"std\"]\n",
    "\n",
    "# wed_stats_df = df_wed.agg(wed_agg_stats)\n",
    "# # tue_stats_df.head()\n",
    "\n",
    "# wed_sharpes = dict()\n",
    "# for tick in wed_stats_df.columns:\n",
    "#    wed_sharpes[tick] = wed_stats_df[tick]['mean']*TAX_RATE / wed_stats_df[tick]['std']\n",
    "# wed_stats_df = wed_stats_df.append(wed_sharpes, ignore_index=True)\n",
    "# wed_stats_df.index = [\"min\", \"max\", \"median\", \"mean\", \"std\", \"sharpe\"]\n",
    "\n",
    "# wed_stats_df = wed_stats_df.transpose()\n",
    "# wed_stats_df.sort_values(axis = 0, by=\"sharpe\", ascending=False)\n",
    "# wed_stats_df\n",
    "\n",
    "# df_thu = pd.DataFrame(backtest_data_thu)\n",
    "# # df_tue.head()\n",
    "\n",
    "# thu_agg_stats = dict()\n",
    "# for x in df_thu.columns:\n",
    "#    thu_agg_stats[x] = [\"min\", \"max\", \"median\", \"mean\", \"std\"]\n",
    "\n",
    "# thu_stats_df = df_thu.agg(thu_agg_stats)\n",
    "# # tue_stats_df.head()\n",
    "\n",
    "# thu_sharpes = dict()\n",
    "# for tick in thu_stats_df.columns:\n",
    "#    thu_sharpes[tick] = thu_stats_df[tick]['mean']*TAX_RATE / thu_stats_df[tick]['std']\n",
    "# thu_stats_df = thu_stats_df.append(thu_sharpes, ignore_index=True)\n",
    "# thu_stats_df.index = [\"min\", \"max\", \"median\", \"mean\", \"std\", \"sharpe\"]\n",
    "\n",
    "# thu_stats_df = thu_stats_df.transpose()\n",
    "# thu_stats_df.sort_values(axis = 0, by=\"sharpe\", ascending=False)\n",
    "# thu_stats_df\n",
    "\n",
    "# df_fri = pd.DataFrame(backtest_data_fri)\n",
    "# fri_agg_stats = dict()\n",
    "# for x in df_fri.columns:\n",
    "#    fri_agg_stats[x] = [\"min\", \"max\", \"median\", \"mean\", \"std\"]\n",
    "\n",
    "# fri_stats_df = df_fri.agg(fri_agg_stats)\n",
    "# # tue_stats_df.head()\n",
    "\n",
    "# fri_sharpes = dict()\n",
    "# for tick in fri_stats_df.columns:\n",
    "#    fri_sharpes[tick] = fri_stats_df[tick]['mean']*TAX_RATE / fri_stats_df[tick]['std']\n",
    "# fri_stats_df = fri_stats_df.append(fri_sharpes, ignore_index=True)\n",
    "# # fri_stats_df\n",
    "# fri_stats_df.index = [\"min\", \"max\", \"median\", \"mean\", \"std\", \"sharpe\"]\n",
    "\n",
    "# fri_stats_df = fri_stats_df.transpose()\n",
    "# fri_stats_df.sort_values(axis = 0, by=\"sharpe\", ascending=False)\n",
    "# fri_stats_df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
